{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test/Val 1 TentaCar</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sim\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "!pip install tflite-runtime opencv-python numpy\n",
    "from tensorflow.lite.python.interpreter import Interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Establecer la conexión\n",
    "Utilizaremos las funciones del API Remoto de COPPELIA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connect(port):\n",
    "# Establece la conexión a COPPELIA\n",
    "# El port debe coincidir con el puerto de conexión en VREP  -- DALE AL PLAY !!!\n",
    "# retorna el número de cliente o -1 si no puede establecer conexión\n",
    "    sim.simxFinish(-1) # just in case, close all opened connections\n",
    "    clientID=sim.simxStart('127.0.0.1',port,True,True,2000,5) # Conectarse\n",
    "    if clientID == 0: print(\"conectado a\", port)\n",
    "    else: print(\"no se pudo conectar\")\n",
    "    return clientID\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectarse al servidor de COPPELIA\n",
    "# *** _Hay que ejecutarlo cada vez que se reinicia la simulación ***\n",
    "sim.simxFinish(-1)\n",
    "client_id = connect(19999)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Clase de Visionado y identificación de objetos</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VisionModuleSim:\n",
    "    def __init__(self, client_id, model_path='efficientdet_lite0.tflite'):\n",
    "        self.client_id = client_id\n",
    "\n",
    "        # Obtener handles       \n",
    "        ret, self.cam_handle = sim.simxGetObjectHandle(self.client_id, 'Prox', sim.simx_opmode_blocking)\n",
    "        ret, self.sensor_handle = sim.simxGetObjectHandle(self.client_id, 'Vision_sensor', sim.simx_opmode_blocking)\n",
    "        \n",
    "        # Inicializar streaming correctamente:\n",
    "        # Para sensor de visión (imagen):\n",
    "        sim.simxGetVisionSensorImage(self.client_id, self.sensor_handle, 0, sim.simx_opmode_streaming)\n",
    "        # Para sensor de proximidad (distancia):\n",
    "        sim.simxReadProximitySensor(self.client_id, self.cam_handle, sim.simx_opmode_streaming)\n",
    "        time.sleep(1)\n",
    "\n",
    "        # Cargar modelo TFLite\n",
    "        self.interpreter = Interpreter(model_path=model_path)\n",
    "        self.interpreter.allocate_tensors()\n",
    "        input_details = self.interpreter.get_input_details()\n",
    "        self.input_index = input_details[0]['index']\n",
    "        self.input_shape = input_details[0]['shape']\n",
    "\n",
    "        output_details = self.interpreter.get_output_details()\n",
    "        self.output_indices = {\n",
    "            'boxes': output_details[0]['index'],\n",
    "            'classes': output_details[1]['index'],\n",
    "            'scores': output_details[2]['index'],\n",
    "            'num_detections': output_details[3]['index'],\n",
    "        }\n",
    "\n",
    "    def preprocess_image(self, image):\n",
    "        img = cv2.resize(image, (self.input_shape[2], self.input_shape[1]))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = img.astype(np.uint8)  # para modelo uint8\n",
    "        img = np.expand_dims(img, axis=0)\n",
    "        return img\n",
    "\n",
    "    def get_detections(self):\n",
    "        # Obtener imagen de la cámara simulada (sensor de visión)\n",
    "        res, resolution, image = sim.simxGetVisionSensorImage(self.client_id, self.sensor_handle, 0, sim.simx_opmode_oneshot_wait)\n",
    "        if res != sim.simx_return_ok:\n",
    "            print(f\"Error al obtener imagen del sensor de visión: {res}\")\n",
    "            return []\n",
    "\n",
    "        img=np.array(image,dtype=np.float32)\n",
    "        img = (1.0 - img) * 255\n",
    "        img = img.astype(np.uint8)\n",
    "        img= img.reshape((resolution[1],resolution[0],3))\n",
    "        img = cv2.flip(img, 0)  # Voltear verticalmente\n",
    "\n",
    "        plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "        plt.title(\"Imagen recibida del sensor\")\n",
    "        plt.show()\n",
    "\n",
    "        input_tensor = self.preprocess_image(img)\n",
    "        self.interpreter.set_tensor(self.input_index, input_tensor)\n",
    "        self.interpreter.invoke()\n",
    "\n",
    "        boxes = self.interpreter.get_tensor(self.output_indices['boxes'])[0]  # [N,4]\n",
    "        classes = self.interpreter.get_tensor(self.output_indices['classes'])[0]  # [N]\n",
    "        scores = self.interpreter.get_tensor(self.output_indices['scores'])[0]  # [N]\n",
    "        num = int(self.interpreter.get_tensor(self.output_indices['num_detections'])[0])\n",
    "\n",
    "        detections = []\n",
    "        for i in range(num):\n",
    "            if scores[i] > 0.3:\n",
    "                ymin, xmin, ymax, xmax = boxes[i]\n",
    "                detections.append({\n",
    "                    'class_id': int(classes[i]),\n",
    "                    'score': scores[i],\n",
    "                    'bbox': (xmin, ymin, xmax, ymax)\n",
    "                })\n",
    "        return detections\n",
    "\n",
    "    def get_nearest_object_distance(self):\n",
    "        # Leer distancia del sensor de proximidad\n",
    "        errorCode, detected, distance_data, _, _ = sim.simxReadProximitySensor(self.client_id, self.cam_handle, sim.simx_opmode_blocking)\n",
    "        print(f\"ErrorCode: {errorCode}, Detectado: {detected}, Datos: {distance_data}\")\n",
    "        if detected:\n",
    "            sensor_val = np.linalg.norm(distance_data)\n",
    "            return round(sensor_val * 100, 2)  # cm\n",
    "        else:\n",
    "            return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Codi Moure Robot</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CarSim:\n",
    "    def __init__(self, client_id):\n",
    "        self.client_id = client_id\n",
    "        self.speed = 2  # rad/s, ajustar según el modelo\n",
    "\n",
    "        # Obtener handles de los motores\n",
    "        ret,self.right_motor=sim.simxGetObjectHandle(self.client_id,'Revolute_joint_right',sim.simx_opmode_blocking)\n",
    "        ret,self.left_motor=sim.simxGetObjectHandle(self.client_id,'Revolute_joint_left',sim.simx_opmode_blocking)\n",
    "        ret,self.back_motor=sim.simxGetObjectHandle(self.client_id,'Revolute_joint_behind',sim.simx_opmode_blocking)\n",
    "\n",
    "    def move_forward(self, duration=0.2):\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.left_motor, self.speed, sim.simx_opmode_streaming)\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.right_motor, self.speed, sim.simx_opmode_streaming)\n",
    "        time.sleep(duration)\n",
    "        self.stop()\n",
    "\n",
    "    def stop(self):\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.left_motor, 0, sim.simx_opmode_streaming)\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.right_motor, 0, sim.simx_opmode_streaming)\n",
    "\n",
    "    def turn_right(self, rotation=1):\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.left_motor, self.speed, sim.simx_opmode_streaming)\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.right_motor, -self.speed, sim.simx_opmode_streaming)\n",
    "        time.sleep(0.2 * rotation)\n",
    "        self.stop()\n",
    "\n",
    "    def turn_left(self, rotation=1):\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.left_motor, -self.speed, sim.simx_opmode_streaming)\n",
    "        sim.simxSetJointTargetVelocity(self.client_id, self.right_motor, self.speed, sim.simx_opmode_streaming)\n",
    "        time.sleep(0.2 * rotation)\n",
    "        self.stop()\n",
    "\n",
    "    def cleanup(self):\n",
    "        self.stop()\n",
    "        sim.simxFinish(self.client_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Codi Deteccions</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parámetros de estilo\n",
    "_MARGIN = 10  # pixeles\n",
    "_ROW_SIZE = 10\n",
    "_FONT_SIZE = 1\n",
    "_FONT_THICKNESS = 1\n",
    "_TEXT_COLOR = (0, 0, 255)  # rojo\n",
    "\n",
    "def visualize_detections(image, detections):\n",
    "    \"\"\"\n",
    "    Dibuja bounding boxes y etiquetas en una imagen (detecciones TFLite).\n",
    "\n",
    "    Args:\n",
    "        image: Imagen RGB (numpy array)\n",
    "        detections: lista de dicts con claves: 'class_id', 'score', 'bbox' (xmin, ymin, xmax, ymax) en [0,1]\n",
    "\n",
    "    Returns:\n",
    "        Imagen con anotaciones\n",
    "    \"\"\"\n",
    "    h, w, _ = image.shape\n",
    "    for det in detections:\n",
    "        xmin, ymin, xmax, ymax = det['bbox']\n",
    "        xmin = int(xmin * w)\n",
    "        xmax = int(xmax * w)\n",
    "        ymin = int(ymin * h)\n",
    "        ymax = int(ymax * h)\n",
    "\n",
    "        # Dibuja caja\n",
    "        cv2.rectangle(image, (xmin, ymin), (xmax, ymax), _TEXT_COLOR, 2)\n",
    "\n",
    "        # Etiqueta\n",
    "        label = f\"{det.get('label', 'obj')} ({round(det['score'], 2)})\"\n",
    "        text_location = (_MARGIN + xmin, _MARGIN + _ROW_SIZE + ymin)\n",
    "        cv2.putText(image, label, text_location, cv2.FONT_HERSHEY_PLAIN,\n",
    "                    _FONT_SIZE, _TEXT_COLOR, _FONT_THICKNESS)\n",
    "\n",
    "    return image\n",
    "\n",
    "# Para mostrar en Jupyter:\n",
    "def show_image_in_jupyter(img_rgb):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.imshow(cv2.cvtColor(img_rgb, cv2.COLOR_BGR2RGB))\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Codi Algoritme Cotxe</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_orientation(image, detection, distancia_cm, fov_deg=60):\n",
    "    _, w, _ = image.shape\n",
    "\n",
    "    xmin, ymin, xmax, ymax = detection['bbox']\n",
    "    cx_px = ((xmin + xmax) / 2) * w\n",
    "    mitad_imagen = w / 2\n",
    "    offset_px = cx_px - mitad_imagen\n",
    "\n",
    "    # Ángulo por píxel\n",
    "    angle_per_pixel = fov_deg / w\n",
    "    orientation_deg = offset_px * angle_per_pixel\n",
    "\n",
    "    return orientation_deg\n",
    "\n",
    "    \n",
    "def calcular_tiempo_rotacion(angulo_deg, velocidad, distancia_entre_ruedas):\n",
    "    theta_rad = math.radians(angulo_deg)\n",
    "    omega = 2 * velocidad / distancia_entre_ruedas\n",
    "    tiempo = abs(theta_rad) / omega\n",
    "    return tiempo\n",
    "    \n",
    "def bug2(client_id, vision_module, car, image, detection):\n",
    "    distance = vision_module.get_nearest_object_distance()\n",
    "    orientation = get_orientation(image, detection, distance)\n",
    "    segundos = calcular_tiempo_rotacion(orientation, 2, 0.03)\n",
    "    if(orientation > 0):\n",
    "        car.turn_right(segundos+0.5)\n",
    "    else:\n",
    "        car.turn_left(segundos+0.5)\n",
    "    time.sleep(0.05)\n",
    "    sim.simxReadProximitySensor(client_id, vision_module.sensor_handle, sim.simx_opmode_streaming)\n",
    "\n",
    "    while True:\n",
    "        distance = vision_module.get_nearest_object_distance()\n",
    "        print(distance)\n",
    "        if distance < 30 and distance != -1:\n",
    "            car.stop()\n",
    "            print(\"Objetivo alcanzado\")\n",
    "            break\n",
    "\n",
    "        orientation = get_orientation(image, detection, distance)\n",
    "        segundos = calcular_tiempo_rotacion(orientation, 2, 0.03)\n",
    "        if(orientation > 0):\n",
    "            car.turn_right(segundos + 0.04)\n",
    "        else:\n",
    "            car.turn_left(segundos + 0.04)\n",
    "        time.sleep(0.1)\n",
    "        car.move_forward()\n",
    "        time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Codi Pinça</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pinca:\n",
    "     def __init__(self, client_id, vision_module):\n",
    "        self.client_id = client_id\n",
    "        self.speed = 2  # rad/s, ajustar según el modelo\n",
    "        self.vision_module = vision_module\n",
    "\n",
    "        # Obtener handles de los motores\n",
    "        ret,self.girar_gancho=sim.simxGetObjectHandle(self.client_id,'gancho1',sim.simx_opmode_blocking)\n",
    "        ret,self.control_gancho=sim.simxGetObjectHandle(self.client_id,'gancho2',sim.simx_opmode_blocking)\n",
    "        ret,self.pinza1=sim.simxGetObjectHandle(self.client_id,'pinza1',sim.simx_opmode_blocking)\n",
    "        ret,self.pinza2=sim.simxGetObjectHandle(self.client_id,'pinza2',sim.simx_opmode_blocking) #servo adicional coppelia\n",
    "\n",
    "     def reset_position(self):\n",
    "        qr0 = 0 * np.pi/180\n",
    "        qr1 = 0 * np.pi/180\n",
    "        qr2 = 0 * np.pi/180\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.girar_gancho, qr0, sim.simx_opmode_oneshot)\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.control_gancho, qr1, sim.simx_opmode_oneshot)\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza1, qr2, sim.simx_opmode_oneshot)\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza2, qr2, sim.simx_opmode_oneshot)\n",
    "    \n",
    "     def home_position(self):\n",
    "        qr0 = 0 * np.pi/180\n",
    "        qr1 = 0 * np.pi/180\n",
    "        qr2 = 0 * np.pi/180\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.girar_gancho, qr0, sim.simx_opmode_oneshot)\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.control_gancho, qr1, sim.simx_opmode_oneshot)\n",
    "\n",
    "     def convert_to_coppelia(self,x,y):\n",
    "        resolution0 = 1280\n",
    "        resolution1 = 720\n",
    "        x_world = (x - resolution0 / 2) / resolution0 * -0.2\n",
    "        y_world = (y - resolution1 / 2) / resolution1 * -0.2\n",
    "        return x_world, y_world\n",
    "        \n",
    "     def dirigir_a(self, x, y, z):\n",
    "      \n",
    "        brazo_fijo = 0.2   # brazo a 45º (fijo)\n",
    "        brazo_movil = 0.2  # brazo que sube y baja\n",
    "        h_base = 0.05       # altura base al suelo\n",
    "    \n",
    "        # 1. Joint 1: rotación base\n",
    "        theta1 = math.atan2(y, x)\n",
    "    \n",
    "        # 2. Pasar coordenadas al plano vertical inclinado a 45°\n",
    "        x_horizontal = math.hypot(x, y)\n",
    "    \n",
    "        # Compensar brazo fijo (offset)\n",
    "        dx = brazo_fijo / math.sqrt(2)\n",
    "        dz = brazo_fijo / math.sqrt(2)\n",
    "    \n",
    "        x2 = x_horizontal - dx\n",
    "        z2 = z - h_base - dz\n",
    "    \n",
    "        # 3. Proyectar al plano del brazo (gira a 45°) → como brazo plano 2D\n",
    "        # En el plano inclinado, transformamos (x2, z2) a coordenadas locales del plano\n",
    "        # Rotación -45º: sistema del brazo\n",
    "        x_local = x2 * math.cos(-math.pi/4) + z2 * math.sin(-math.pi/4)\n",
    "        z_local = -x2 * math.sin(-math.pi/4) + z2 * math.cos(-math.pi/4)\n",
    "    \n",
    "        # 4. Ángulo para Joint 2 (cinemática inversa plana 1DOF)\n",
    "        if z_local > brazo_movil:\n",
    "            print(\"¡Punto fuera del alcance!\")\n",
    "            return None\n",
    "    \n",
    "        # Consideramos el brazo como girando desde el eje 0 hacia abajo\n",
    "        theta2 = math.atan2(z_local, x_local)\n",
    "    \n",
    "        # Convertir a grados\n",
    "        theta1_deg = math.degrees(theta1)\n",
    "        theta2_deg = math.degrees(theta2)\n",
    "    \n",
    "        return theta1_deg, theta2_deg\n",
    "\n",
    "     def gripper(self, open_close):\n",
    "        if open_close == 1: #abrir\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza1, 30, sim.simx_opmode_blocking)\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza2, -30, sim.simx_opmode_blocking)\n",
    "        elif open_close == 0: #cerrar\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza1, -2, sim.simx_opmode_blocking)\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza2, 2, sim.simx_opmode_blocking)\n",
    "        else: #reset\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza1, 0, sim.simx_opmode_blocking)\n",
    "            returnCode = sim.simxSetJointTargetPosition(self.client_id, self.pinza2, 0, sim.simx_opmode_blocking)\n",
    "\n",
    "\n",
    "     def agafar_objecte(self):\n",
    "        detections = self.vision_module.get_detections()\n",
    "        detection = detections[0]\n",
    "        _, _, image = sim.simxGetVisionSensorImage(client_id, self.vision_module.sensor_handle, 0, sim.simx_opmode_oneshot_wait)\n",
    "        img=np.array(image,dtype=np.float32)\n",
    "        img = (1.0 - img) * 255\n",
    "        img = img.astype(np.uint8)\n",
    "        img= img.reshape((resolution[1],resolution[0],3))\n",
    "        img = cv2.flip(img, -1)\n",
    "        h , w, _ = img.shape\n",
    "        xmin, ymin, xmax, ymax = detection['bbox']\n",
    "        cx_px = ((xmin + xmax) / 2) * w\n",
    "        cy_px = ((ymin + ymax) / 2) * h\n",
    "        x, y = self.convert_to_coppelia(cx_px, cy_px)\n",
    "        print(x, y)\n",
    "        theta1_deg, theta2_deg = self.dirigir_a(x, y)\n",
    "        print(theta1_deg, theta2_deg)\n",
    "        q = [0,0]\n",
    "        q[0] = theta1_deg*np.pi/180\n",
    "        q[1] = theta2_deg*np.pi/180\n",
    "        \n",
    "        self.gripper(1) #abrir pinza\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.girar_gancho, q[0], sim.simx_opmode_blocking)\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.control_gancho, q[1], sim.simx_opmode_blocking)\n",
    "        time.sleep(2)\n",
    "        self.gripper(0) #cerrar pinza\n",
    "        time.sleep(1)\n",
    "        self.home_position()\n",
    "        returnCode = sim.simxSetJointTargetPosition(self.client_id, self.girar_gancho, np.pi, sim.simx_opmode_blocking)\n",
    "        time.sleep(0.5)\n",
    "        self.gripper(1) #abrir pinza\n",
    "        time.sleep(3)\n",
    "        self.gripper(2) #reset pinza\n",
    "        self.reset_position()\n",
    "        \n",
    "        \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 1. Validación de la cámara</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vision_module = VisionModuleSim(client_id)\n",
    "\n",
    "res, resolution, image = sim.simxGetVisionSensorImage(client_id, vision_module.sensor_handle, 0, sim.simx_opmode_oneshot_wait)\n",
    "print(f\"Lectura imagen res: {res}, resolution: {resolution}\")\n",
    "assert res == sim.simx_return_ok, \"❌ No se pudo obtener imagen del sensor\"\n",
    "print(\"✅ Test 2: Imagen de cámara recibida\")\n",
    "\n",
    "# Mostrar imagen\n",
    "img=np.array(image,dtype=np.float32)\n",
    "img = (1.0 - img) * 255\n",
    "img = img.astype(np.uint8)\n",
    "img= img.reshape((resolution[1],resolution[0],3))\n",
    "img = cv2.flip(img, -1)\n",
    "show_image_in_jupyter(img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 2. Validación Detección Objetos</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = vision_module.get_detections()\n",
    "print(f\"✅ Test 2: Detecciones obtenidas ({len(detections)} objetos detectados)\")\n",
    "if(len(detections))> 0:\n",
    "    print(detections[0]['bbox'])\n",
    "assert isinstance(detections, list), \"❌ Las detecciones no son una lista\"\n",
    "for d in detections:\n",
    "    assert 'bbox' in d and 'score' in d and 'class_id' in d, \"❌ Formato de detección inválido\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 3. Validación Lectura Sensor Proximidad</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = vision_module.get_nearest_object_distance()\n",
    "print(f\"✅ Test 3: Distancia detectada: {distance} cm\")\n",
    "assert isinstance(distance, (float, int)), \"❌ La distancia no es un número\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 4. Validación Movimiento Coche</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "car = CarSim(client_id)\n",
    "\n",
    "print(\"Moviendo hacia adelante...\")\n",
    "car.move_forward(3)\n",
    "\n",
    "print(\"Parado...\")\n",
    "car.stop()\n",
    "\n",
    "print(\"Girando a la izquierda...\")\n",
    "car.turn_left(5)\n",
    "\n",
    "print(\"Parado...\")\n",
    "car.stop()\n",
    "\n",
    "print(\"Girando a la derecha...\")\n",
    "car.turn_right(10)\n",
    "\n",
    "print(\"Parado...\")\n",
    "car.stop()\n",
    "\n",
    "print(\"✅ Test 4: Movimiento completado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 5. Validación Decisión Coche</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(detections) > 0:\n",
    "    print(\"✅ Objeto detectado con IA\")\n",
    "elif 0 < distance < 1.5:\n",
    "    print(\"⚠️ Posible pared detectada por sensor\")\n",
    "else:\n",
    "    print(\"ℹ️ Nada detectado\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Test 6. Validación Buscar Objeto</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detections2 = []\n",
    "speed = 2\n",
    "radio_rueda = 0.05 # en coppelia\n",
    "while len(detections2) == 0:\n",
    "    detections2 = vision_module.get_detections()\n",
    "    print(f\"Detecciones obtenidas ({len(detections2)} objetos detectados)\")\n",
    "    if len(detections2) > 0:\n",
    "        break\n",
    "\n",
    "    segundos = calcular_tiempo_rotacion(90, 2, 0.03)\n",
    "    print(segundos)\n",
    "    car.turn_right(1)\n",
    "    time.sleep(2)\n",
    "\n",
    "distance = vision_module.get_nearest_object_distance()\n",
    "print(f\"Distancia detectada: {distance} cm\")\n",
    "res, resolution, image = sim.simxGetVisionSensorImage(client_id, vision_module.sensor_handle, 0, sim.simx_opmode_oneshot_wait)\n",
    "img = np.array(image, dtype=np.float32)\n",
    "img = (1.0 - img) * 255          \n",
    "img = img.astype(np.uint8)\n",
    "img = img.reshape((resolution[1], resolution[0], 3))\n",
    "img = cv2.flip(img, 0)\n",
    "bug2(client_id, vision_module, car, img, detections2[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Test 7: Agafar un objecte</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinza = Pinca(client_id, vision_module)\n",
    "pinza.agafar_objecte()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
